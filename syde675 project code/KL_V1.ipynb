{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d62886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import Resize\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "from einops.layers.torch import Rearrange\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4f240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "x_train = load('x_train.npy')\n",
    "y_train = load('y_train.npy')\n",
    "x_test = load('x_test.npy')\n",
    "y_test = load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be96fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebadbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset( Tensor(x_train), Tensor(y_train).long() )\n",
    "dataset_test = TensorDataset( Tensor(x_test), Tensor(y_test).long())\n",
    "\n",
    "\n",
    "image_size = 224\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Apply transformations to custom datasets\n",
    "dataset_train.transform = train_transform\n",
    "dataset_test.transform = test_transform\n",
    "\n",
    "# Create DataLoader objects\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True).to()\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Vision Transformer model\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, image_size, patch_size, num_classes, dim):\n",
    "        super(ViT, self).__init__()\n",
    "        self.patch_embedding = nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size)\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.positional_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=dim, nhead=8), num_layers=6)\n",
    "        self.fc = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)  # Transpose dimensions to match expected input shape\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.patch_embedding(x)\n",
    "        x = rearrange(x, 'b c h w -> b (h w) c')  # flatten spatial dimensions\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.positional_embedding\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x[:, 0]  # take the cls token\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64\n",
    "image_size = 224\n",
    "patch_size = 16\n",
    "num_classes = 2\n",
    "dim = 768\n",
    "num_epochs = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c49fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = ViT(image_size, patch_size, num_classes, dim)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e9258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
