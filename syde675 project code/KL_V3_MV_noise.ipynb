{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3d62886",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3d62886",
    "outputId": "df9c5170-1cca-4c49-a161-189057eb11aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vit-pytorch in c:\\users\\kaka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.38.1)\n",
      "Requirement already satisfied: torch>=1.10 in c:\\users\\kaka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from vit-pytorch) (1.10.2)\n",
      "Requirement already satisfied: einops>=0.4.1 in c:\\users\\kaka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from vit-pytorch) (0.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\kaka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from vit-pytorch) (0.11.3)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\kaka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from torch>=1.10->vit-pytorch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kaka\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from torch>=1.10->vit-pytorch) (3.7.4.3)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\kaka\\appdata\\roaming\\python\\python36\\site-packages (from torchvision->vit-pytorch) (8.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\kaka\\appdata\\roaming\\python\\python36\\site-packages (from torchvision->vit-pytorch) (1.19.5)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mobilevit_pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a5d6eec28787>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mvit_pytorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmobile_vit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMobileViT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmobilevit_pytorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMobileViT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mobilevit_pytorch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import Resize\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "from torch import Tensor\n",
    "#!pip install einops\n",
    "!pip install vit-pytorch\n",
    "from torchvision.models import resnet18\n",
    "#from vit_pytorch.mobile_vit import MobileViT\n",
    "from vit_pytorch.vit_for_small_dataset import ViT\n",
    "\n",
    "\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4f240a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef4f240a",
    "outputId": "fe7853ce-acb8-4606-aea2-ed55db87da1d"
   },
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# images = load('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/x_train.npy')\n",
    "# labels = load('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/y_train.npy')\n",
    "\n",
    "######### KL colab\n",
    "images = load('/content/drive/MyDrive/Colab_data/data_256/x_train.npy')\n",
    "labels = load('/content/drive/MyDrive/Colab_data/data_256/y_train.npy')\n",
    "\n",
    "# images = load('x_train.npy')\n",
    "# labels = load('y_train.npy')\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "x_train = x_train.reshape((-1,3,256,256))\n",
    "x_test = x_test.reshape((-1,3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2681bf10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2681bf10",
    "outputId": "a03cf5ea-5609-47ee-d9ac-9c0f18617b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 3, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be96fd6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be96fd6b",
    "outputId": "667d2caa-4e1b-4d1f-ee66-74c02aa7394c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebadbe99",
   "metadata": {
    "id": "ebadbe99"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "image_size = 256\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop((256, 256), scale=(0.7, 1.0), ratio=(0.9, 1.1)),  # Random crop and resize\n",
    "    transforms.RandomRotation(degrees=(-10, 10), fill=(0,0,0)),  # Random rotation with black fill\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.5, saturation=0.1),  # Random color adjustments\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop((256, 256), scale=(0.7, 1.0), ratio=(0.9, 1.1)),  # Random crop and resize\n",
    "    transforms.RandomRotation(degrees=(-10, 10), fill=(0,0,0)),  # Random rotation with black fill\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.5, saturation=0.1),  # Random color adjustments\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Apply transformations to custom datasets\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "x_train_processed = torch.stack([train_transform(image) for image in x_train_tensor])\n",
    "x_test_processed = torch.stack([val_transform(image) for image in x_test_tensor])\n",
    "\n",
    "\n",
    "# Create DataLoader objects\n",
    "batch_size = 64\n",
    "\n",
    "dataset_train = TensorDataset( x_train_processed, Tensor(y_train).long() )\n",
    "dataset_test = TensorDataset( x_test_processed, Tensor(y_test).long())\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c49fe8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c49fe8e",
    "outputId": "77278619-1971-4d90-fd6e-41abd949430f"
   },
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "num_epochs = 300\n",
    "\n",
    "train_loss_rec = np.zeros(num_epochs)\n",
    "train_acc_rec =np.zeros(num_epochs) \n",
    "test_acc_rec = np.zeros(num_epochs)\n",
    "# model  = MobileViT(\n",
    "#     image_size = (256, 256),\n",
    "#     dims = [96, 120, 144],\n",
    "#     channels = [16, 32, 48, 48, 64, 64, 80, 80, 96, 96, 384],\n",
    "#     num_classes = 2).to(device)\n",
    "model = ViT(\n",
    "    image_size = 256,\n",
    "    patch_size = 16,\n",
    "    num_classes = 1000,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), lr=1e-4, weight_decay=2e-2)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "    train_loss_rec[epoch] = running_loss/len(train_loader)\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f\"train_Accuracy: {100 * train_correct / train_total}%\")\n",
    "    print(f\"test_Accuracy: {100 * test_correct / test_total}%\")\n",
    "    train_acc_rec[epoch] =train_correct / train_total \n",
    "    test_acc_rec[epoch] =test_correct / test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5036837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = load('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/x_test.npy')\n",
    "y_test = load('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/y_test.npy')\n",
    "\n",
    "x_test = x_test.reshape((-1,3,256,256))\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "x_test_processed = torch.stack([test_transform(image) for image in x_test_tensor])\n",
    "\n",
    "dataset_test = TensorDataset( x_test, Tensor(y_test).long())\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb79cff",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Evaluation\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "test_acc =test_correct / test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e9258",
   "metadata": {
    "id": "0b8e9258"
   },
   "outputs": [],
   "source": [
    "from numpy import save\n",
    "\n",
    "save('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/Mvit_noise_train_loss_rec.npy', train_loss_rec)\n",
    "save('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/Mvit_noise_train_acc_rec.npy', train_acc_rec)\n",
    "save('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/Mvit_noise_val_acc_rec.npy', test_acc_rec)\n",
    "save('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/Mvit_noise_test_acc.npy', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46adb80",
   "metadata": {
    "id": "a46adb80"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
