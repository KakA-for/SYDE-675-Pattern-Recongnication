{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e3d62886",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3d62886",
        "outputId": "1c7e4ba1-6a73-4fce-92b4-ca201455a851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vit-pytorch\n",
            "  Downloading vit_pytorch-1.6.5-py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.7.0 (from vit-pytorch)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from vit-pytorch) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from vit-pytorch) (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->vit-pytorch) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->vit-pytorch) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->vit-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->vit-pytorch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, einops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, vit-pytorch\n",
            "Successfully installed einops-0.7.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 vit-pytorch-1.6.5\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Compose\n",
        "from torchvision.transforms import Resize\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader , TensorDataset\n",
        "from torch import Tensor\n",
        "#!pip install einops\n",
        "!pip install vit-pytorch\n",
        "from torchvision.models import resnet18\n",
        "from vit_pytorch.mobile_vit import MobileViT\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ef4f240a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef4f240a",
        "outputId": "8e953d43-7293-4b30-eb97-b750124a75ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from numpy import load\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# images = load('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/x_train.npy')\n",
        "# labels = load('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/y_train.npy')\n",
        "\n",
        "######### KL colab\n",
        "images = load('/content/drive/MyDrive/Colab_data/data_256/x_train.npy')\n",
        "labels = load('/content/drive/MyDrive/Colab_data/data_256/y_train.npy')\n",
        "\n",
        "# images = load('x_train.npy')\n",
        "# labels = load('y_train.npy')\n",
        "\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "x_train = x_train.reshape((-1,3,256,256))\n",
        "x_test = x_test.reshape((-1,3,256,256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2681bf10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2681bf10",
        "outputId": "7eaa5579-7e04-4b7f-9feb-bb50737f2dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2880, 3, 256, 256)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(np.shape(x_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "be96fd6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be96fd6b",
        "outputId": "5064ea82-570a-4071-a8e1-f6c4af8a394d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ebadbe99",
      "metadata": {
        "id": "ebadbe99"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "image_size = 256\n",
        "\n",
        "# Define transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomResizedCrop((256, 256), scale=(0.7, 1.0), ratio=(0.9, 1.1)),  # Random crop and resize\n",
        "    transforms.RandomRotation(degrees=(-10, 10), fill=(0,0,0)),  # Random rotation with black fill\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.5, saturation=0.1),  # Random color adjustments\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Apply transformations to custom datasets\n",
        "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
        "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
        "x_train_processed = torch.stack([train_transform(image) for image in x_train_tensor])\n",
        "x_test_processed = torch.stack([val_transform(image) for image in x_test_tensor])\n",
        "\n",
        "\n",
        "# Create DataLoader objects\n",
        "batch_size = 32\n",
        "\n",
        "dataset_train = TensorDataset( x_train_processed, Tensor(y_train).long() )\n",
        "dataset_test = TensorDataset( x_test_processed, Tensor(y_test).long())\n",
        "\n",
        "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2c49fe8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2c49fe8e",
        "outputId": "bd2f2ffb-81d9-4b59-9e64-e3d72ed5f0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25, Loss: 0.6858626034524705\n",
            "train_Accuracy: 56.21527777777778%\n",
            "test_Accuracy: 52.42718446601942%\n",
            "Epoch 2/25, Loss: 0.676419919066959\n",
            "train_Accuracy: 60.451388888888886%\n",
            "test_Accuracy: 54.78502080443828%\n",
            "Epoch 3/25, Loss: 0.662520147032208\n",
            "train_Accuracy: 60.38194444444444%\n",
            "test_Accuracy: 56.03328710124827%\n",
            "Epoch 4/25, Loss: 0.6417212340566847\n",
            "train_Accuracy: 69.30555555555556%\n",
            "test_Accuracy: 53.81414701803051%\n",
            "Epoch 5/25, Loss: 0.5928008218606313\n",
            "train_Accuracy: 78.4375%\n",
            "test_Accuracy: 55.20110957004161%\n",
            "Epoch 6/25, Loss: 0.4788246439562904\n",
            "train_Accuracy: 87.5%\n",
            "test_Accuracy: 51.59500693481276%\n",
            "Epoch 7/25, Loss: 0.36059484829505284\n",
            "train_Accuracy: 82.56944444444444%\n",
            "test_Accuracy: 48.12760055478502%\n",
            "Epoch 8/25, Loss: 0.28563511437839934\n",
            "train_Accuracy: 94.79166666666667%\n",
            "test_Accuracy: 56.72676837725381%\n",
            "Epoch 9/25, Loss: 0.20405228129691547\n",
            "train_Accuracy: 95.55555555555556%\n",
            "test_Accuracy: 52.704576976421635%\n",
            "Epoch 10/25, Loss: 0.16722088704506557\n",
            "train_Accuracy: 97.95138888888889%\n",
            "test_Accuracy: 54.50762829403606%\n",
            "Epoch 11/25, Loss: 0.1450041766795847\n",
            "train_Accuracy: 97.74305555555556%\n",
            "test_Accuracy: 53.25936199722607%\n",
            "Epoch 12/25, Loss: 0.11640015292084879\n",
            "train_Accuracy: 99.02777777777777%\n",
            "test_Accuracy: 52.42718446601942%\n",
            "Epoch 13/25, Loss: 0.10771672185510398\n",
            "train_Accuracy: 98.64583333333333%\n",
            "test_Accuracy: 52.843273231622746%\n",
            "Epoch 14/25, Loss: 0.10049981149948306\n",
            "train_Accuracy: 99.20138888888889%\n",
            "test_Accuracy: 50.48543689320388%\n",
            "Epoch 15/25, Loss: 0.09384142462578085\n",
            "train_Accuracy: 98.92361111111111%\n",
            "test_Accuracy: 50.624133148404994%\n",
            "Epoch 16/25, Loss: 0.09166643053500188\n",
            "train_Accuracy: 99.6875%\n",
            "test_Accuracy: 53.398058252427184%\n",
            "Epoch 17/25, Loss: 0.0653702483408981\n",
            "train_Accuracy: 99.72222222222223%\n",
            "test_Accuracy: 49.79195561719833%\n",
            "Epoch 18/25, Loss: 0.059231516972391145\n",
            "train_Accuracy: 99.16666666666667%\n",
            "test_Accuracy: 53.25936199722607%\n",
            "Epoch 19/25, Loss: 0.053736633916075034\n",
            "train_Accuracy: 99.09722222222223%\n",
            "test_Accuracy: 51.31761442441054%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-275714b5a198>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtrain_loss_rec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize model, loss, and optimizer\n",
        "num_epochs = 25\n",
        "\n",
        "train_loss_rec = np.zeros(num_epochs)\n",
        "train_acc_rec =np.zeros(num_epochs)\n",
        "test_acc_rec = np.zeros(num_epochs)\n",
        "model  = MobileViT(\n",
        "    image_size = (256, 256),\n",
        "    dims = [64, 80, 96],\n",
        "    channels = [16, 16, 24, 24, 48, 48, 64, 64, 80, 80, 320],\n",
        "    num_classes = 2,).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.RAdam(model.parameters(), lr=1e-4, weight_decay=2e-2)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
        "    train_loss_rec[epoch] = running_loss/len(train_loader)\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"train_Accuracy: {100 * train_correct / train_total}%\")\n",
        "    print(f\"test_Accuracy: {100 * test_correct / test_total}%\")\n",
        "    train_acc_rec[epoch] =train_correct / train_total\n",
        "    test_acc_rec[epoch] =test_correct / test_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5036837f",
      "metadata": {
        "id": "5036837f"
      },
      "outputs": [],
      "source": [
        "x_test = load('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/x_test.npy')\n",
        "y_test = load('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/y_test.npy')\n",
        "\n",
        "x_test = x_test.reshape((-1,3,256,256))\n",
        "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
        "x_test_processed = torch.stack([test_transform(image) for image in x_test_tensor])\n",
        "\n",
        "dataset_test = TensorDataset( x_test, Tensor(y_test).long())\n",
        "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb79cff",
      "metadata": {
        "id": "cfb79cff"
      },
      "outputs": [],
      "source": [
        " # Evaluation\n",
        "model.eval()\n",
        "\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_acc =test_correct / test_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b8e9258",
      "metadata": {
        "id": "0b8e9258"
      },
      "outputs": [],
      "source": [
        "from numpy import save\n",
        "\n",
        "# save('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/Mvit_noise_train_loss_rec.npy', train_loss_rec)\n",
        "# save('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/Mvit_noise_train_acc_rec.npy', train_acc_rec)\n",
        "# save('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/Mvit_noise_val_acc_rec.npy', test_acc_rec)\n",
        "# save('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/Mvit_noise_test_acc.npy', test_acc)\n",
        "\n",
        "save('/content/drive/MyDrive/Colab_data/data_256/Mvit_noise_train_loss_rec.npy', train_loss_rec)\n",
        "save('/content/drive/MyDrive/Colab_data/data_256/Mvit_noise_train_acc_rec.npy', train_acc_rec)\n",
        "save('/content/drive/MyDrive/Colab_data/data_256/Mvit_noise_val_acc_rec.npy', test_acc_rec)\n",
        "save('/content/drive/MyDrive/Colab_data/data_256/Mvit_noise_test_acc.npy', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a46adb80",
      "metadata": {
        "id": "a46adb80"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}