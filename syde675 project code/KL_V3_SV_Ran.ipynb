{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "jKqn5kyivd7J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jKqn5kyivd7J",
    "outputId": "26d8bcb4-16f7-4870-8745-5f8adc6f85a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3d62886",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3d62886",
    "outputId": "c8592e52-8152-4a0b-baa4-73df09019d95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vit-pytorch\n",
      "  Downloading vit_pytorch-1.6.5-py3-none-any.whl (100 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/100.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m92.2/100.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting einops>=0.7.0 (from vit-pytorch)\n",
      "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from vit-pytorch) (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from vit-pytorch) (0.17.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10->vit-pytorch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10->vit-pytorch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10->vit-pytorch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10->vit-pytorch)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10->vit-pytorch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10->vit-pytorch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10->vit-pytorch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10->vit-pytorch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10->vit-pytorch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10->vit-pytorch)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10->vit-pytorch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit-pytorch) (2.2.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->vit-pytorch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->vit-pytorch) (1.25.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->vit-pytorch) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->vit-pytorch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->vit-pytorch) (1.3.0)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, einops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, vit-pytorch\n",
      "Successfully installed einops-0.7.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 vit-pytorch-1.6.5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import Resize\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "from torch import Tensor\n",
    "#!pip install einops\n",
    "!pip install vit-pytorch\n",
    "from torchvision.models import resnet18\n",
    "from vit_pytorch.vit_for_small_dataset import ViT\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4f240a",
   "metadata": {
    "id": "ef4f240a"
   },
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "images = load('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/x_train.npy')\n",
    "labels = load('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/y_train.npy')\n",
    "\n",
    "######### KL colab\n",
    "# images = load('/content/drive/MyDrive/Colab_data/data_256/x_train.npy')\n",
    "# labels = load('/content/drive/MyDrive/Colab_data/data_256/y_train.npy')\n",
    "\n",
    "# images = load('x_train.npy')\n",
    "# labels = load('y_train.npy')\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "x_train = x_train.reshape((-1,3,256,256))\n",
    "x_test = x_test.reshape((-1,3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2681bf10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2681bf10",
    "outputId": "ca4ea7f7-c61f-4866-e631-55f7cb6f58ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 3, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be96fd6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be96fd6b",
    "outputId": "61949d1c-4d5e-48b4-bfbd-eaa3fefd892c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebadbe99",
   "metadata": {
    "id": "ebadbe99"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "image_size = 256\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomResizedCrop((256, 256), scale=(0.7, 1.0), ratio=(0.9, 1.1)),  # Random crop and resize\n",
    "#     transforms.RandomRotation(degrees=(-10, 10), fill=(0,0,0)),  # Random rotation with black fill\n",
    "#     transforms.ColorJitter(brightness=0.1, contrast=0.5, saturation=0.1),  # Random color adjustments\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Apply transformations to custom datasets\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "x_train_processed = torch.stack([train_transform(image) for image in x_train_tensor])\n",
    "x_test_processed = torch.stack([val_transform(image) for image in x_test_tensor])\n",
    "\n",
    "\n",
    "# Create DataLoader objects\n",
    "batch_size = 64\n",
    "\n",
    "dataset_train = TensorDataset( x_train_processed, Tensor(y_train).long() )\n",
    "dataset_test = TensorDataset( x_test_processed, Tensor(y_test).long())\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c49fe8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c49fe8e",
    "outputId": "0e986041-2742-4bdf-9af2-a4e6f9e49e05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, Loss: 0.7261422965261671\n",
      "train_Accuracy: 53.541666666666664%\n",
      "test_Accuracy: 53.536754507628295%\n",
      "Epoch 2/300, Loss: 0.719366619322035\n",
      "train_Accuracy: 50.416666666666664%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 3/300, Loss: 0.7404756095674303\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 4/300, Loss: 0.6925245417488946\n",
      "train_Accuracy: 53.229166666666664%\n",
      "test_Accuracy: 53.81414701803051%\n",
      "Epoch 5/300, Loss: 0.6899994995858935\n",
      "train_Accuracy: 56.354166666666664%\n",
      "test_Accuracy: 54.92371705963939%\n",
      "Epoch 6/300, Loss: 0.7022954185803731\n",
      "train_Accuracy: 57.083333333333336%\n",
      "test_Accuracy: 54.50762829403606%\n",
      "Epoch 7/300, Loss: 0.6951371908187867\n",
      "train_Accuracy: 57.361111111111114%\n",
      "test_Accuracy: 57.004160887656035%\n",
      "Epoch 8/300, Loss: 0.6924878809187147\n",
      "train_Accuracy: 53.09027777777778%\n",
      "test_Accuracy: 54.78502080443828%\n",
      "Epoch 9/300, Loss: 0.696595287322998\n",
      "train_Accuracy: 54.270833333333336%\n",
      "test_Accuracy: 54.09153952843273%\n",
      "Epoch 10/300, Loss: 0.6835997197363112\n",
      "train_Accuracy: 54.270833333333336%\n",
      "test_Accuracy: 54.230235783633844%\n",
      "Epoch 11/300, Loss: 0.6850494503974914\n",
      "train_Accuracy: 55.90277777777778%\n",
      "test_Accuracy: 54.64632454923717%\n",
      "Epoch 12/300, Loss: 0.6867972135543823\n",
      "train_Accuracy: 53.263888888888886%\n",
      "test_Accuracy: 54.230235783633844%\n",
      "Epoch 13/300, Loss: 0.6856577025519477\n",
      "train_Accuracy: 55.38194444444444%\n",
      "test_Accuracy: 54.36893203883495%\n",
      "Epoch 14/300, Loss: 0.6940112604035271\n",
      "train_Accuracy: 56.354166666666664%\n",
      "test_Accuracy: 54.50762829403606%\n",
      "Epoch 15/300, Loss: 0.6894279652171664\n",
      "train_Accuracy: 56.388888888888886%\n",
      "test_Accuracy: 54.64632454923717%\n",
      "Epoch 16/300, Loss: 0.6984226266543071\n",
      "train_Accuracy: 50.729166666666664%\n",
      "test_Accuracy: 51.59500693481276%\n",
      "Epoch 17/300, Loss: 0.6913163118892246\n",
      "train_Accuracy: 53.888888888888886%\n",
      "test_Accuracy: 51.73370319001387%\n",
      "Epoch 18/300, Loss: 0.6874962700737848\n",
      "train_Accuracy: 53.298611111111114%\n",
      "test_Accuracy: 54.230235783633844%\n",
      "Epoch 19/300, Loss: 0.6843485077222188\n",
      "train_Accuracy: 51.84027777777778%\n",
      "test_Accuracy: 52.1497919556172%\n",
      "Epoch 20/300, Loss: 0.6880439533127679\n",
      "train_Accuracy: 55.104166666666664%\n",
      "test_Accuracy: 54.50762829403606%\n",
      "Epoch 21/300, Loss: 0.682345802254147\n",
      "train_Accuracy: 54.861111111111114%\n",
      "test_Accuracy: 53.398058252427184%\n",
      "Epoch 22/300, Loss: 0.683489645851983\n",
      "train_Accuracy: 50.03472222222222%\n",
      "test_Accuracy: 51.17891816920943%\n",
      "Epoch 23/300, Loss: 0.6869677821795146\n",
      "train_Accuracy: 54.201388888888886%\n",
      "test_Accuracy: 54.64632454923717%\n",
      "Epoch 24/300, Loss: 0.681570823987325\n",
      "train_Accuracy: 57.326388888888886%\n",
      "test_Accuracy: 58.25242718446602%\n",
      "Epoch 25/300, Loss: 0.6835206495390997\n",
      "train_Accuracy: 57.74305555555556%\n",
      "test_Accuracy: 56.03328710124827%\n",
      "Epoch 26/300, Loss: 0.6836752679612902\n",
      "train_Accuracy: 57.5%\n",
      "test_Accuracy: 58.11373092926491%\n",
      "Epoch 27/300, Loss: 0.6837486214107937\n",
      "train_Accuracy: 53.611111111111114%\n",
      "test_Accuracy: 54.36893203883495%\n",
      "Epoch 28/300, Loss: 0.6827414128515455\n",
      "train_Accuracy: 57.291666666666664%\n",
      "test_Accuracy: 55.33980582524272%\n",
      "Epoch 29/300, Loss: 0.6831344352828131\n",
      "train_Accuracy: 51.458333333333336%\n",
      "test_Accuracy: 49.79195561719833%\n",
      "Epoch 30/300, Loss: 0.6866785566012065\n",
      "train_Accuracy: 57.84722222222222%\n",
      "test_Accuracy: 56.171983356449374%\n",
      "Epoch 31/300, Loss: 0.6873814993434482\n",
      "train_Accuracy: 54.270833333333336%\n",
      "test_Accuracy: 52.28848821081831%\n",
      "Epoch 32/300, Loss: 0.6847616712252299\n",
      "train_Accuracy: 57.5%\n",
      "test_Accuracy: 57.697642163661584%\n",
      "Epoch 33/300, Loss: 0.6850921445422702\n",
      "train_Accuracy: 56.49305555555556%\n",
      "test_Accuracy: 55.0624133148405%\n",
      "Epoch 34/300, Loss: 0.6892062624295553\n",
      "train_Accuracy: 53.75%\n",
      "test_Accuracy: 54.09153952843273%\n",
      "Epoch 35/300, Loss: 0.6895937151379056\n",
      "train_Accuracy: 57.43055555555556%\n",
      "test_Accuracy: 57.83633841886269%\n",
      "Epoch 36/300, Loss: 0.6905822210841709\n",
      "train_Accuracy: 53.05555555555556%\n",
      "test_Accuracy: 53.536754507628295%\n",
      "Epoch 37/300, Loss: 0.6908517824278937\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 38/300, Loss: 0.694448110792372\n",
      "train_Accuracy: 55.69444444444444%\n",
      "test_Accuracy: 56.171983356449374%\n",
      "Epoch 39/300, Loss: 0.6960959381527371\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 40/300, Loss: 0.6975946068763733\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 41/300, Loss: 0.6936153080728319\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 42/300, Loss: 0.6963348242971632\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 43/300, Loss: 0.6936822030279371\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 44/300, Loss: 0.6951366861661276\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 45/300, Loss: 0.6947243478563097\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 46/300, Loss: 0.6931050048934089\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 47/300, Loss: 0.6961806111865574\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 48/300, Loss: 0.6938455462455749\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 49/300, Loss: 0.6935466567675272\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 50/300, Loss: 0.6936436878310309\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 51/300, Loss: 0.6940152857038709\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 52/300, Loss: 0.6935010035832723\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 53/300, Loss: 0.6936147385173373\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 54/300, Loss: 0.6932665083143447\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 55/300, Loss: 0.6940760903888279\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 56/300, Loss: 0.6933793385823568\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 57/300, Loss: 0.6939108636644151\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 58/300, Loss: 0.6934075885348849\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 59/300, Loss: 0.6932706991831462\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 60/300, Loss: 0.6931024074554444\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 61/300, Loss: 0.6933378206359015\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 62/300, Loss: 0.6932987928390503\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 63/300, Loss: 0.6932260155677795\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 64/300, Loss: 0.6932175861464607\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 65/300, Loss: 0.6932178775469462\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 66/300, Loss: 0.6932922350035773\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 67/300, Loss: 0.6931547350353665\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 68/300, Loss: 0.6932137688000997\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 69/300, Loss: 0.6931703580750359\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 70/300, Loss: 0.6931247591972352\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 71/300, Loss: 0.6932293348842197\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 72/300, Loss: 0.6931559549437629\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 73/300, Loss: 0.6931758509741889\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 74/300, Loss: 0.6931549972958035\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 75/300, Loss: 0.6931733780437046\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 76/300, Loss: 0.6931906316015456\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 77/300, Loss: 0.6931827836566501\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 78/300, Loss: 0.6931746204694113\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 79/300, Loss: 0.6931343873341879\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 80/300, Loss: 0.6931931257247925\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 81/300, Loss: 0.6931721422407362\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 82/300, Loss: 0.6931609948476155\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 83/300, Loss: 0.6931778682602776\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 84/300, Loss: 0.6932335337003072\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 85/300, Loss: 0.6931833651330735\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 86/300, Loss: 0.6931822101275126\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 87/300, Loss: 0.6931686176194085\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 88/300, Loss: 0.6931182503700256\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 89/300, Loss: 0.6931660837597318\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 90/300, Loss: 0.6932083355055915\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 91/300, Loss: 0.693176641729143\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 92/300, Loss: 0.6931689076953464\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 93/300, Loss: 0.6931386325094435\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 94/300, Loss: 0.6931509137153625\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 95/300, Loss: 0.6931898050838047\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 96/300, Loss: 0.6931691116756863\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 97/300, Loss: 0.6931542224354215\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 98/300, Loss: 0.6931769953833686\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 99/300, Loss: 0.6931517044703166\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 100/300, Loss: 0.6931670043203566\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 101/300, Loss: 0.6931606372197469\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 102/300, Loss: 0.6931644863552517\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 103/300, Loss: 0.6931588874922858\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 104/300, Loss: 0.6932146297560797\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 105/300, Loss: 0.6931640969382392\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 106/300, Loss: 0.6931538833512201\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 107/300, Loss: 0.6931923733817207\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 108/300, Loss: 0.6931854433483547\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 109/300, Loss: 0.6931613590982225\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 110/300, Loss: 0.6931580384572347\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 111/300, Loss: 0.6931512819396125\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 112/300, Loss: 0.6931835783852471\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 113/300, Loss: 0.6931410590807597\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 114/300, Loss: 0.6931680705812242\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 115/300, Loss: 0.693148152033488\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 116/300, Loss: 0.6931475241978963\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 117/300, Loss: 0.693148057990604\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 118/300, Loss: 0.6931794087092081\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 119/300, Loss: 0.6931825055016412\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 120/300, Loss: 0.6931838737593756\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 121/300, Loss: 0.6931373649173312\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 122/300, Loss: 0.6931415266460843\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 123/300, Loss: 0.6931680772039626\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 124/300, Loss: 0.6931393596861097\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 125/300, Loss: 0.6931708441840277\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 126/300, Loss: 0.6931847585572137\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 127/300, Loss: 0.6931309143702189\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 128/300, Loss: 0.6931638373268976\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 129/300, Loss: 0.6931299924850464\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 130/300, Loss: 0.6931463334295485\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 131/300, Loss: 0.6931379424201117\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 132/300, Loss: 0.6931654002931383\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 133/300, Loss: 0.6931326773431566\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 134/300, Loss: 0.6931759423679775\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 135/300, Loss: 0.6931349423196581\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 136/300, Loss: 0.6931598199738397\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 137/300, Loss: 0.6931820021735298\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 138/300, Loss: 0.6931754615571764\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 139/300, Loss: 0.6931316971778869\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 140/300, Loss: 0.6931636373202006\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 141/300, Loss: 0.6931446499294704\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 142/300, Loss: 0.6931690480973985\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 143/300, Loss: 0.6931650347179836\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 144/300, Loss: 0.6931338959270054\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 145/300, Loss: 0.6931278573142158\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 146/300, Loss: 0.6931705448362563\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 147/300, Loss: 0.693149189154307\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 148/300, Loss: 0.6931318932109409\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 149/300, Loss: 0.6932184749179416\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 150/300, Loss: 0.6931417187054952\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 151/300, Loss: 0.6931645353635152\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 152/300, Loss: 0.693186202314165\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 153/300, Loss: 0.6931290639771356\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 154/300, Loss: 0.6931631909476386\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 155/300, Loss: 0.6931405478053623\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 156/300, Loss: 0.6931961920526293\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 157/300, Loss: 0.6931350840462579\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 158/300, Loss: 0.6932022266917759\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 159/300, Loss: 0.6931421240170796\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 160/300, Loss: 0.6931611365742154\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 161/300, Loss: 0.6931398007604811\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 162/300, Loss: 0.6931531389554342\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 163/300, Loss: 0.6932140549023946\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 164/300, Loss: 0.6932607505056593\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 165/300, Loss: 0.6931847929954529\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 166/300, Loss: 0.6931475639343262\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 167/300, Loss: 0.6931747900115119\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 168/300, Loss: 0.6931623803244696\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 169/300, Loss: 0.6931354549196032\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 170/300, Loss: 0.693148132165273\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 171/300, Loss: 0.6931495891677009\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 172/300, Loss: 0.693142671055264\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 173/300, Loss: 0.6931646982828776\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 174/300, Loss: 0.6931753330760532\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 175/300, Loss: 0.6931689355108474\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 176/300, Loss: 0.6931957973374261\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 177/300, Loss: 0.6931914620929294\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 178/300, Loss: 0.6931901693344116\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 179/300, Loss: 0.6932885024282668\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 180/300, Loss: 0.6932258499993218\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 181/300, Loss: 0.6931742774115668\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 182/300, Loss: 0.6932037565443251\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 183/300, Loss: 0.6932130363252428\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 184/300, Loss: 0.6931473109457228\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 185/300, Loss: 0.6931426697307163\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 186/300, Loss: 0.6931513984998067\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 187/300, Loss: 0.6931375318103367\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 188/300, Loss: 0.6931452698177761\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 189/300, Loss: 0.6931426564852396\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 190/300, Loss: 0.6931479904386733\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 191/300, Loss: 0.6932477249039544\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 192/300, Loss: 0.6932990537749396\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 193/300, Loss: 0.6933105601204766\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 194/300, Loss: 0.6932426850001018\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 195/300, Loss: 0.6931673460536533\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 196/300, Loss: 0.6932527383168539\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 197/300, Loss: 0.6931674400965373\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 198/300, Loss: 0.6932541847229003\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 199/300, Loss: 0.6934325589074029\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 200/300, Loss: 0.6931715501679314\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 201/300, Loss: 0.6931991775830587\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 202/300, Loss: 0.6931680308447944\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 203/300, Loss: 0.693135666847229\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 204/300, Loss: 0.6931538065274556\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 205/300, Loss: 0.6931715713606941\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 206/300, Loss: 0.6932611889309354\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 207/300, Loss: 0.693156463570065\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 208/300, Loss: 0.6932340674930149\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 209/300, Loss: 0.6934511886702643\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 210/300, Loss: 0.6932072228855557\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 211/300, Loss: 0.6933248996734619\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 212/300, Loss: 0.6932164218690661\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 213/300, Loss: 0.6931604663530986\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 214/300, Loss: 0.6931536118189494\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 215/300, Loss: 0.6931971841388278\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 216/300, Loss: 0.6932917051845127\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 217/300, Loss: 0.6931740509139167\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 218/300, Loss: 0.6931925468974643\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 219/300, Loss: 0.6932161132494609\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 220/300, Loss: 0.6931845943133036\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 221/300, Loss: 0.6932813631163703\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 222/300, Loss: 0.6931833359930251\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 223/300, Loss: 0.6934918032752143\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 224/300, Loss: 0.6931145562065972\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 225/300, Loss: 0.6932755642467074\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 226/300, Loss: 0.6931547045707702\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 227/300, Loss: 0.6934227956665887\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 228/300, Loss: 0.6932675706015693\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 229/300, Loss: 0.6932377047008939\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 230/300, Loss: 0.6932602882385254\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 231/300, Loss: 0.6933146913846334\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 232/300, Loss: 0.6935703105396694\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 233/300, Loss: 0.6932171199056837\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 234/300, Loss: 0.6931529257032606\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 235/300, Loss: 0.693358318010966\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 236/300, Loss: 0.6931886659728156\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 237/300, Loss: 0.6931689725981818\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 238/300, Loss: 0.6931966463724772\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 239/300, Loss: 0.6932259890768263\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 240/300, Loss: 0.6932142986191644\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 241/300, Loss: 0.6931887441211276\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 242/300, Loss: 0.6932711362838745\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 243/300, Loss: 0.6931174370977614\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 244/300, Loss: 0.6933181179894341\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 245/300, Loss: 0.693158335155911\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 246/300, Loss: 0.6931673208872478\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 247/300, Loss: 0.6933497309684753\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 248/300, Loss: 0.6936328013737997\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 249/300, Loss: 0.6932774199379815\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 250/300, Loss: 0.6933089998033312\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 251/300, Loss: 0.6936687323782179\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 252/300, Loss: 0.6934036533037822\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 253/300, Loss: 0.6932850387361315\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 254/300, Loss: 0.6932281931241353\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 255/300, Loss: 0.6932550681961908\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 256/300, Loss: 0.6932032201025221\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 257/300, Loss: 0.6932425671153598\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 258/300, Loss: 0.6936874972449408\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 259/300, Loss: 0.693239438533783\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 260/300, Loss: 0.6935293475786845\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 261/300, Loss: 0.6936723947525024\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 262/300, Loss: 0.6932038903236389\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 263/300, Loss: 0.6933400763405694\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 264/300, Loss: 0.6935462130440606\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 265/300, Loss: 0.694169635242886\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 266/300, Loss: 0.6934676766395569\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 267/300, Loss: 0.693329992559221\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 268/300, Loss: 0.6934371829032898\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 269/300, Loss: 0.6937734047571819\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 270/300, Loss: 0.6932778848542107\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 271/300, Loss: 0.6934264924791124\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 272/300, Loss: 0.6936821791860792\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 273/300, Loss: 0.6933468831910028\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 274/300, Loss: 0.6932410809728834\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 275/300, Loss: 0.6931909852557712\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 276/300, Loss: 0.6934859328799777\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 277/300, Loss: 0.6932104176945156\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 278/300, Loss: 0.6931639154752095\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 279/300, Loss: 0.6932014306386312\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 280/300, Loss: 0.6932123753759596\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 281/300, Loss: 0.6930521329243978\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 282/300, Loss: 0.6933410750495063\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 283/300, Loss: 0.6932187530729506\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 284/300, Loss: 0.6932388742764791\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 285/300, Loss: 0.6932418809996711\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 286/300, Loss: 0.694036230776045\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 287/300, Loss: 0.6928924441337585\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 288/300, Loss: 0.6933876633644104\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 289/300, Loss: 0.6931773159239027\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 290/300, Loss: 0.6931953019566006\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 291/300, Loss: 0.6931734217537774\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 292/300, Loss: 0.693188832865821\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 293/300, Loss: 0.6933377318912082\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 294/300, Loss: 0.6936823447545369\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 295/300, Loss: 0.6933699793285794\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 296/300, Loss: 0.6933739026387532\n",
      "train_Accuracy: 49.61805555555556%\n",
      "test_Accuracy: 50.762829403606105%\n",
      "Epoch 297/300, Loss: 0.6933418936199612\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 298/300, Loss: 0.6934979438781739\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 299/300, Loss: 0.693655953142378\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n",
      "Epoch 300/300, Loss: 0.6934384346008301\n",
      "train_Accuracy: 50.38194444444444%\n",
      "test_Accuracy: 49.237170596393895%\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "num_epochs = 300\n",
    "\n",
    "train_loss_rec = np.zeros(num_epochs)\n",
    "train_acc_rec =np.zeros(num_epochs)\n",
    "test_acc_rec = np.zeros(num_epochs)\n",
    "# model  = MobileViT(\n",
    "#     image_size = (256, 256),\n",
    "#     dims = [96, 120, 144],\n",
    "#     channels = [16, 32, 48, 48, 64, 64, 80, 80, 96, 96, 384],\n",
    "#     num_classes = 2).to(device)\n",
    "model = ViT(\n",
    "    image_size = 256,\n",
    "    patch_size = 16,\n",
    "    num_classes = 2,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RAdam(model.parameters(), lr=1e-3, weight_decay=2e-2)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Free up GPU memory\n",
    "        del images, labels, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "    train_loss_rec[epoch] = running_loss/len(train_loader)\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Free up GPU memory\n",
    "            del images, labels, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Free up GPU memory\n",
    "            del images, labels, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"train_Accuracy: {100 * train_correct / train_total}%\")\n",
    "    print(f\"test_Accuracy: {100 * test_correct / test_total}%\")\n",
    "    train_acc_rec[epoch] =train_correct / train_total\n",
    "    test_acc_rec[epoch] =test_correct / test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5036837f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "5036837f",
    "outputId": "d8e6fe80-6b76-4d4d-d1f7-34f1031473a8"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9a3157724157>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_test_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdataset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "x_test = load('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/x_test.npy')\n",
    "y_test = load('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/y_test.npy')\n",
    "\n",
    "x_test = x_test.reshape((-1,3,256,256))\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "x_test_processed = torch.stack([test_transform(image) for image in x_test_tensor])\n",
    "\n",
    "dataset_test = TensorDataset( x_test, Tensor(y_test).long())\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb79cff",
   "metadata": {
    "id": "cfb79cff"
   },
   "outputs": [],
   "source": [
    " # Evaluation\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Free up GPU memory\n",
    "        del images, labels, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "test_acc =test_correct / test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e9258",
   "metadata": {
    "id": "0b8e9258"
   },
   "outputs": [],
   "source": [
    "from numpy import save\n",
    "\n",
    "save('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/SV_train_loss_rec.npy', train_loss_rec)\n",
    "save('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/Sv_train_acc_rec.npy', train_acc_rec)\n",
    "save('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/Sv_val_acc_rec.npy', test_acc_rec)\n",
    "save('/content/drive/My Drive/SYDE675_Leaf_Disease_Classification/KL_data/SV_test_acc.npy', test_acc)\n",
    "\n",
    "# save('/content/drive/MyDrive/Colab_data/data_256/SV_train_loss_rec.npy', train_loss_rec)\n",
    "# save('/content/drive/MyDrive/Colab_data/data_256/Sv_train_acc_rec.npy', train_acc_rec)\n",
    "# save('/content/drive/MyDrive/Colab_data/data_256/Sv_val_acc_rec.npy', test_acc_rec)\n",
    "# save('/content/drive/MyDrive/Colab_data/data_256/SV_test_acc.npy', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46adb80",
   "metadata": {
    "id": "a46adb80"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
